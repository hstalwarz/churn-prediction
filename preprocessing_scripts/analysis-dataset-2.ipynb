{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Notebook contains code for creating dataset 2 for churn prediction analysis, having features based on  user logs defined monthwise, and those based on transaction logs defined in aggregate, both for a period of 6 months before the churn prediction period (March 2017). Since the prediction period is the month of March, we consider users whose subscription was due to expire in Feb 2017, in accordance with our definition of churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the pre-processed user logs file\n",
    "user_log_reader = pd.read_csv(\"user_logs_initial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename index column (since this is the user identifier, msno)\n",
    "user_log_reader.rename(columns={'Unnamed: 0':'msno'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_log_reader.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the pre-processed file, containing churn labels for users whose subscription was due to expire in Feb 2017\n",
    "user_target_expiration = pd.read_csv(\"train_v2_final_201702.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get user logs for the target users\n",
    "user_log_reader_reduced = user_log_reader.merge(user_target_expiration, on = 'msno', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_log_reader_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the transaction logs file\n",
    "transaction_log_reader = pd.read_csv(\"transactions_log_initial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join with transactiton logs data\n",
    "combined_logs_df = user_log_reader_reduced.merge(transaction_log_reader, on = 'msno', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make temporary file for this data, so that there is limited data stored in memory\n",
    "combined_logs_df.to_csv(\"combined_logs_initial.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file\n",
    "combined_logs_reader = pd.read_csv(\"combined_logs_initial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the pre-processed membership details file\n",
    "members_pre_reader = pd.read_csv(\"members_pre.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge member demographics into the existing data\n",
    "analysis_dataset = combined_logs_reader.merge(members_pre_reader, on = 'msno', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if we have the expected number of dimensions\n",
    "analysis_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns generated from indexes\n",
    "analysis_data = analysis_data[analysis_data.columns.difference(['Unnamed: 0', 'Unnamed: 0.1'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the data to csv\n",
    "analysis_data.to_csv(\"analysis_dataset2.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
